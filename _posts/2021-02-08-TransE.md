---
layout: distill
title: "[지식그래프] (TransE) Translating Embeddings for Modeling Multi-relational Data"
categories: 
  - 지식그래프 

toc: true
toc_sticky: true
toc_label: 목차
use_math: true
date: '2021-02-08 23:27:23'
comments: true
---

Bordes, Antoine, et al. "Translating embeddings for modeling multi-relational data." Neural Information Processing Systems (NIPS). 2013.


### _In short, "Embedding Entities and Relationships in Same space"_

### About

이 논문은 지식 그래프에서 가장 기반이 되는 Translation-based model 이라고 할 수 있고, 저 차원의 벡터 공간에서 가볍고 성능이 좋은 모델을 제시하는데 의의가 있다.  

### Abstract

지금 우리가 해결할 문제는 구성요소와 관계들을 저차원의 벡터 공간으로 임베딩 시키는 것이고, 무엇보다 지식 그래프의 기반이 되고 학습하기 쉬운 장점을 가지는 것을 목표로 한다. 이에 TransE 라는 모델을 제시하는데 이 모델은 **relationship**(관계)를  저차원의 임베딩된 구성요소간 **translations**(전환)  으로 해석한다는 것이 핵심이다.

### 1. Introduction

#### Modeling multi-realtional data
* Multi-relational data 란 무엇일까?  

단어에서 유추할 수 있듯이 많은 관계를 표현하는게 우선시되어 보인다. 이는, **directed graph**(방향을 가진 그래프) 에서 nodes와 edges를 entities(head, tail), label로 표현한 것으로 다음과 같이 나타낼 수 있다.  $(head, label, tail)$ 의 의미를 가진 $(h,l,t)$ 로 간략화 할 수 있고 주로 사회 네트워크 망이나 친구 관계, 소셜 네트워크 등에서 주로 사용된다. 이때 우리의 목표는 KB, 지식 그래프에서 발생하는 다수의 관계를 효과적으로 모델링하여 새로운 정보가 들어오면 별도의 지식없이 자동적으로 정보를 업데이트 해주는 것이다.   

이때, realtional data, 즉 관계를 가지는 데이터에서 중요한점은 locality, 국소적인 관계에 있어 구성요소와 관계가 서로 다른 타입의 데이터를 동시에 가질 수 있다는 점이다. 이에 multi-relational, 다양한 관계를 가진 데이터를 표현할 때는 좀 더 일반적인 접근이 필요하다. 그리고 추천시스템에서 주로 다루는 Matrix factorization  의 성질을 이용한 single, multi-realtional 관계 표현에 이어 2013년에 발표된 '*A semantic matching energy function for learning with multi-realtional data*'에 의하면,  복잡하고 여러 타입의 데이터 타입이 포함된 multi-relational 도메인에서 linear하고 simple한 모델이 정확성과 확장성 사이의 절충을 더욱 잘 표현할 수 있음을 시사한다.  

![image](https://user-images.githubusercontent.com/68312164/107507619-2eb08280-6be3-11eb-8b54-e25b7d8f54e3.png)

#### Relationships as translations in the embedding space
이 논문에서 제시하는 TransE라는 energy-based 모델은  구성요소들의 저차원 임베딩을 학습하는데 의의를 가지고 관계들을 임베딩 공간에서의 전환으로 표현될 수 있다. 이때 핵심은 **$(h,l,t)$가 성립한다면, $h+l \approx t$** 가 성립한다는 점이다. 즉, **임베딩 된 tail entity $t$는 임베딩 된 head entity $h$ 와 realtionship 과 관련된 벡터 $l$ 과의 합과 가까이 위치한다**는 의미로 볼 수 있다.  

이 식에 대한 모티베이션은 간단히 두 가지 인데 아래와 같다.  
1. 지식그래프에서 흔히 볼 수 있는 계층적인 관계(부모-자식, 자녀 관계)를 잘 표현할 수 있는게 결국, translation 이다.  
2. 노드 타입이 다른 1-to-1 관계를 좀 더 용이하게  표현할 수 있는게 역시, translation 이다.  


### 2. Translation-based model

 훈련 데이터 셋에서 모델의 핵심은 구성 요소들과 관계를 잘 나타내는 저차원의 벡터 임베딩을 학습하는 것이다. 머신러닝에서 항상 그래왔듯, 학습을 하기 위해서는 손실 함수가 정의 되어야고 정의된 손실함수가 어느 방향(최소화 방향) 으로 학습을 진행하면 될지를 알려주는 이정표가 될 것이다. 이 때 손실함수는 margin-based ranking criterion 으로 정의하는데 목적식을 정의하기 이전에 다음과 같은 맥락을 이해해야 한다.  
 
 * $$h,t\in E $$(set of entities), $$l \in L $$(set of relationships) 
 * 임베딩 벡터의 차원: $$\mathbb{R}^{k} $$(k는 실험자 지정 하이퍼파라미터)
 * energy of triplet: $$d(h+l, t)$$, $$d$$는 dissimilarity measure로 주로 $$L_{1}, L_{2} - norm$$
 * $$\gamma $$는 margin hyperparameter
 
 
 $$ \mathcal{L}= \sum_{(h,l,t)\in S} \sum_{(h',l,t')\in S'_{(h,l,t)}}\left [ \gamma +{d} \mathbf{(h+l,t)} -d\mathbf{(h'+l,t')})\right ]_{+} $$ 
 
 이때,  
 
 $$S'_{(h,l,t)} = \left \{ (h',l,t)|h' \in E \right \} \cup \left \{ (h,l,t')|t' \in E \right \} $$  
 
 위의 Set은 Corrupted triplet이라고 할 수 있는데, 이때 Corrupted 는 '노이즈가 있는' 상태라고 이해하면 될 것 같다. head 와 tail 중 하나의 요소만 랜덤한 entity 값으로 변경해주고 각각의 경우를 합하여 하나의 집합으로 표현한 Set으로 이해하면 된다. 또한, 위의 Loss function에서 우리는 training triplet $(h,l,t)$ 의 energy(dissimilarity) 가 낮은 상황, $(h',l,t')$ 의 energy(dissimilarity) 가 높은 상황을 원하므로 위의 손실 함수가 합리적으로 정의된 면모를 확인할 수 있다. 최적화는 mini-batch의 SGD를 통해 일어나게 되고, $L_{2}$-norm 을 1로 제한한다.  상세한 최적화 알고리즘은 아래와 같다.
 
<center><img src="https://user-images.githubusercontent.com/68312164/107486444-652cd400-6bc8-11eb-98f5-3a72be295145.png" width="750" height="500"></center>

간략히 이해해보면,  
(1) relationship 을 표현하는 집합 내 원소인 l 에 대해서 유니폼 분포를 따르게 해주고, 정규화 해준다.   
(2) Entity Set 내의 구성요소 역시 유니폼 분포 내에 특정 값을 가지게 해준다.  
(3) 구성요소를 정규화 해주고, minibatch size인 b로 training set $(h,l,t)$ 가 b개 있는 $S_{batch}$ 를 구성하고, $T_{batch}$를 초기화 시켜준다.  
(4) $S_{batch}$ 안에 있는 모든 triplet에 대해 각각 Corrupted 된 Set을 만들어주고 $T_{batch}$ 에 원소로 넣어준다.  
(5) 구성된 $T_{batch}$를 통해 편미분한 목적식을 바탕으로 임베딩을 업데이트 시켜준다.  
(6) (2) - (5) 를 반복한다.  

이러한 TransE 는 기존의 제시된 SE *(Learning structured embeddings of knowledge bases, 2013)* 모델 보다 설명력은 약할 수 있지만, 관계를 더욱 잘 반영한다는 점과 임베딩된 모델에 대한 최적화가 어렵다는 점에서 기존의 SE보다 우월함을 가지게 된다. 이러한 TransE는 간단하면서도 효과적인 모델로 이해할 수 있는데, 2-way interactions를 표현하는데 있어 강점을 가진다. 반면 ,$h,l,t$ 간의 상호종속적인 관계, 3-way dependencies를 표현하는데는 약점을 가진다. 또한 1-to-1 이상의 , 1-to-N, N-to-1 관계를 포함하는데 TransE는 부적합할 수 있다.

### 3. Conclusion
저자는 지식그래프 임베딩의 새로운 학습 관점을 제시하였다. 계층적인 관계를 표현하기 위해 최소한의 변수들을 바탕으로 기존의 지식 그래프 모델들보다 효과적인 퍼포먼스를 보여주었다. 또한, 가벼운 모델을 바탕으로 확장성또한 TransE만의 강점이라고 표현할 수 있다. 

### 세 줄 요약
1. Relationships = 저차원의 임베딩 공간에서의 Translations
2. Corrupted Triplet 도입하여 손실 함수 정의
3. 가볍고, 성능 좋음. 1-to-1에 효과적이라는 한계

### References
1. Bordes, Antoine, et al. "Translating embeddings for modeling multi-relational data." Neural Information Processing Systems (NIPS). 2013.
